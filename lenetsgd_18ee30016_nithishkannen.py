# -*- coding: utf-8 -*-
"""LeNetSGD_18EE30016_NithishKannen.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A8N2DOwM3VpX2vn02BrCh0KBKo91mEj8
"""

#### Name : Nithish Kannen S
#### Roll Number: 18EE30016

#Imports
import torch
import numpy as np
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import seaborn as sns

train_dataset = datasets.MNIST(root='./data', 
                                           train=True, 
                                           transform=transforms.ToTensor(),  
                                           download=True)
test_dataset = datasets.MNIST(root='./data', 
                                           train=False, 
                                           transform=transforms.ToTensor(),  
                                           download=True)

### This is the DataLoader which is a class that loads the Dataset in Batches of Fixed size
### This helps us to Forward Propogate and Backporogate a fixed number of training samples at a time
train_loader_256 = DataLoader(dataset = train_dataset, batch_size = 256, shuffle = True)
train_loader_128 = DataLoader(dataset = train_dataset, batch_size = 128, shuffle = True)
train_loader_64 = DataLoader(dataset = train_dataset, batch_size = 64, shuffle = True)

##Thought the batch size of test dataset wont make a difference, it is there for memory issues
test_loader = DataLoader(dataset = test_dataset, batch_size = 256, shuffle = True)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

print("Number of Train datapoints: {}".format(str(len(train_loader_64.dataset))))
print("Number of Test datapoints: {}".format(str(len(test_loader.dataset))))

class CNN(nn.Module):
    """
    This is the CNN Class of the folowing specifications
    Convolution layer 1: 5*5, with 6output channels
    •MaxPool1: 2*2, stride=2•Convolution layer 2: 5*5, with 16output channels•MaxPool1: 2*2, stride=2
    •Linear   Layer1:input(calculate   yourself   based   on   conv   and   pooling   layer), output=120
    •Linear Layer2: input= 120, output=84•Linear Layer1: input=84, output=10
    •Use ReLU as activation function in each convolution and linear layer•Input: MNIST data (28*28)
    
    Note: Here we do same padding, i.e the Height and Width of Layer remains same before 
    and after the convolution layer. The Height and Width reduces only during Maxpooling operation
    """
    def __init__(self,num_channels):
        """
        This is the constructor, that initalises the Different Layers of the CNN
        Instance with the specified values passes as params
        args: num_channels: number of channels in the Input Data
        """
        super(CNN,self).__init__()
        self.cnn1 = nn.Conv2d(num_channels, 6, (5,5),padding = (2,2)) ## same padding
        self.pool = nn.MaxPool2d(kernel_size = (2,2), stride = (2,2)) ##
        self.cnn2 = nn.Conv2d(6, 16, (5,5), padding = (2,2)) ## same padding
        self.fc1 = nn.Linear(16*7*7, 120)
        self.fc2 = nn.Linear(120,84)
        self.fc3 = nn.Linear(84,10)
        
    def forward(self, x):
        """
        Function to feedward the input through the CNN operations
        args: x : input
        returns output
        """
        x = F.relu(self.cnn1(x))###(256,6,28,28)
        x = self.pool(x) ###(256,6,14,14)
        x = F.relu(self.cnn2(x))##(256,16,14,14)
        x = self.pool(x)###(256, 16, 7, 7)
        x = x.view(x.shape[0], -1) ##(256, 16*7*7)
        x = F.relu(self.fc1(x))##(256, 120)
        x = F.relu(self.fc2(x))###(256,84)
        x = (self.fc3(x)) ##(256,10)
        
        return x

learning_rate1 = 0.025
learning_rate2 = 0.05
learning_rate3 = 0.1
learning_rate4 = 0.2
learning_rate5 =  0.5

def test_accuracy(model, loader, flag, test):
    """
    This function tests accuarcy for a given model, the parameters decide if it is for the training or the
    testing data
    It returns the Percentage accuracy of the Given Model for the given data

    """
    data = 60000
    if(test):
      data = 10000
    correct_pred = 0

    for X, y in loader:

        X = X.to(device)
        y = y.to(device)
        #X = X.view(X.shape[0], -1)
        logits = model.forward(X)
        predictions = torch.argmax(logits, dim = 1)
        correct_pred += torch.sum(predictions == y)

    return correct_pred/data*100

def test_loss(model, loader, flag, test):
    """
    This function tests loss for a given model, the parameters decide if it is for the training or the
    testing data
    It returns the Loss per Batch of the Given Model for the given data

    """
    data = 60000
    if(test):
      data = 10000
    running_loss = 0
    
    for batch_index, (X, y) in enumerate(loader):

        X = X.to(device)
        y = y.to(device)
        #X = X.view(X.shape[0], -1)
        logits = model.forward(X)
        predictions = torch.argmax(logits, dim = 1)
        running_loss += loss(logits, y)

    


    return running_loss/(batch_index + 1)

"""## Question **3**"""

### This Cell is the Training Cell, we use the SGD Optimizer and train the Network for 50 Epochs
### Learning Rate = 0.5, Batch Size = 64


model = CNN(1).to(device)
loss = nn.CrossEntropyLoss()
optimizer = optim.SGD( model.parameters(), lr = learning_rate5,  momentum=0.9 )
EPOCHS = 50
train_loss =  []
train_acc = []
test_acc = []
test_losses = []

print(" Batch Size = 64 \n")

for epoch in range(EPOCHS):
    

    running_loss = 0
    correct_predictions = 0
    
    for batch_index, (image_data, classes) in enumerate(train_loader_64):
        
        X = image_data.to(device)
        y = classes.to(device)
        
        #X = X.view(X.shape[0], -1)  ## do this for the FCC part
        
        logits = model.forward(X)
        
        predictions = torch.argmax(logits, dim = 1)
        
        running_loss += loss(logits, y)
        
        #print(classes)
        correct_predictions += torch.sum(predictions == y)
        
        optimizer.zero_grad()
        
    totalLoss = running_loss/(batch_index + 1)
    
    totalLoss.backward()
    
    optimizer.step()
    
    epoch_loss = running_loss.item()/(batch_index + 1)
    epoch_acc = correct_predictions/(60000)
    
    train_loss.append(epoch_loss)
    train_acc.append(epoch_acc)
    test_acc.append(test_accuracy(model, test_loader, 0, True).item())
    test_losses.append(test_loss(model, test_loader, 0, True).item())
    
    print("Epoch: {} ........... Training Accuracy: {:.4f}%.....Training Loss: {:.4f}.....Test Accuracy : {:.4f}%... TestLoss : {:.4f} ".format(epoch + 1, epoch_acc*100, epoch_loss, test_accuracy(model, test_loader, 0, True).item(), (test_loss(model, test_loader, 0, True).item())))

"""## Question 4"""

print("Training Accuracy : {}".format(train_acc[49].item()))
print("Test Accuracy : {}".format(test_acc[49]))
print("Training Loss : {}".format(train_loss[49]))
print("Testing Loss : {}".format(test_losses[49]))

"""## Question **5**"""

fig = plt.figure(figsize = (16, 5)) 
    #plt.title("Learning Rate = 0.1",  fontsize = 20,fontname="Times New Roman Bold")
plt.subplot(121)
plt.plot( range(EPOCHS), train_loss,'b-',label='Training') 
plt.legend()
plt.title("Training Loss vs EPOCHS", fontsize = 20,fontname="Times New Roman Bold")
plt.xlabel('Epochs', fontsize = 16)
plt.ylabel('Loss', fontsize = 16)

plt.subplot(122)
plt.plot(range(EPOCHS), test_losses,'r-',label='Testing') 
plt.legend()
plt.title("Testing Loss vs EPOCHS", fontsize = 20,fontname="Times New Roman Bold")
plt.xlabel('Epochs ',fontsize = 16)
plt.ylabel('Loss', fontsize = 16)



"""# **Question 6 A - Deciding Batch Size**

a)

Batch size = 256

I have separately trained and tested the Data for Different Batch sizes,
We consder 3 batch Sizes, 256, 128 and 64
"""

TestAcc = []
TrainAcc = []

model = CNN(1).to(device)
loss = nn.CrossEntropyLoss()
optimizer = optim.SGD( model.parameters(), lr = learning_rate3,  momentum=0.9 )
EPOCHS = 50
train_loss =  []
train_acc = []
test_acc = []

print(" Batch Size = 256 \n")

for epoch in range(EPOCHS):
    

    running_loss = 0
    correct_predictions = 0
    
    for batch_index, (image_data, classes) in enumerate(train_loader_256):
        
        X = image_data.to(device)
        y = classes.to(device)
        
        #X = X.view(X.shape[0], -1)  ## do this for the FCC part
        
        logits = model.forward(X)
        
        predictions = torch.argmax(logits, dim = 1)
        
        running_loss += loss(logits, y)
        
        #print(classes)
        correct_predictions += torch.sum(predictions == y)
        
        optimizer.zero_grad()
        
    totalLoss = running_loss/(batch_index + 1)
    
    totalLoss.backward()
    
    optimizer.step()
    
    epoch_loss = running_loss.item()/(batch_index + 1)
    epoch_acc = correct_predictions/(60000)
    
    train_loss.append(epoch_loss)
    train_acc.append(epoch_acc)
    test_acc.append(test_accuracy(model, test_loader, 0, True).item())
    
    print("Epoch: {} ........... Training Accuracy: {:.4f}%.....Training Loss: {:.4f}.....Test Accuracy : {:.4f}%".format(epoch + 1, epoch_acc*100, epoch_loss, test_accuracy(model, test_loader, 0,True).item()))

def visualise(EPOCHS, train_loss, train_acc, test_acc, batch_size): 

    print("Batch Size : ", batch_size)
    fig = plt.figure(figsize = (19, 4)) 
    plt.title("Learning Rate = 0.1",  fontsize = 20,fontname="Times New Roman Bold")
    plt.subplot(131)
    plt.plot(range(EPOCHS),train_loss,'r-',label='Loss/error') 
    plt.legend(loc='upper right')
    plt.title("Training Loss vs Epoch", fontsize = 20,fontname="Times New Roman Bold")
    plt.xlabel('Epochs', fontsize = 16)
    plt.ylabel('Loss', fontsize = 16)
    
    plt.subplot(132)
    plt.plot(range(EPOCHS),train_acc,'g-',label='Accuracy') 
    plt.legend()
    plt.title("Training Accuracy vs Epoch", fontsize = 20,fontname="Times New Roman Bold")
    plt.xlabel('Epochs',fontsize = 16)
    plt.ylabel('Acc', fontsize = 16)

    plt.subplot(133)
    plt.plot(range(EPOCHS),test_acc,'b-',label='Accuracy') 
    plt.legend()
    plt.title("Testing Accuracy vs Epoch", fontsize = 20,fontname="Times New Roman Bold")
    plt.xlabel('Epochs',fontsize = 16)
    plt.ylabel('Acc', fontsize = 16)

visualise(EPOCHS, train_loss, train_acc, test_acc, 256)

TestAcc.append(test_accuracy(model, test_loader, 0, True).item())
TrainAcc.append(test_accuracy(model, train_loader_256, 0, False).item())
print("Batch Size = 256\n")
print(" Testing Accuracy: {:.4f}%   :   Training Accuracy: {:.4f}% ".format(test_accuracy(model, test_loader, 0, True).item(), test_accuracy(model, train_loader_256, 0, False).item()))

"""**Batch size = 128**"""

model = CNN(1).to(device)
loss = nn.CrossEntropyLoss()
optimizer = optim.SGD( model.parameters(), lr = learning_rate3,  momentum=0.9 )
EPOCHS = 50
train_loss =  []
train_acc = []
test_acc = []

print(" Batch Size = 128 \n")

for epoch in range(EPOCHS):
    

    running_loss = 0
    correct_predictions = 0
    
    for batch_index, (image_data, classes) in enumerate(train_loader_128):
        
        X = image_data.to(device)
        y = classes.to(device)
        
        #X = X.view(X.shape[0], -1)  ## do this for the FCC part
        
        logits = model.forward(X)
        
        predictions = torch.argmax(logits, dim = 1)
        
        running_loss += loss(logits, y)
        
        #print(classes)
        correct_predictions += torch.sum(predictions == y)
        
        optimizer.zero_grad()
        
    totalLoss = running_loss/(batch_index + 1)
    
    totalLoss.backward()
    
    optimizer.step()
    
    epoch_loss = running_loss.item()/(batch_index + 1)
    epoch_acc = correct_predictions/(60000)
    
    train_loss.append(epoch_loss)
    train_acc.append(epoch_acc)
    test_acc.append(test_accuracy(model, test_loader, 0, True).item())
    
    print("Epoch: {} ........... Training Accuracy: {:.4f}%.....Training Loss: {:.4f}.....Test Accuracy : {:.4f}%".format(epoch + 1, epoch_acc*100, epoch_loss, test_accuracy(model, test_loader, 0 ,True).item()))

visualise(EPOCHS, train_loss, train_acc, test_acc, 128)

TestAcc.append(test_accuracy(model, test_loader, 0, True).item())
TrainAcc.append(test_accuracy(model, train_loader_256, 0, False).item())
print("Batch Size = 128\n")
print(" Testing Accuracy: {:.4f}%   :   Training Accuracy: {:.4f}% ".format(test_accuracy(model, test_loader, 0, True).item(), test_accuracy(model, train_loader_256, 0, False).item()))

"""Batch Size = 64"""

model = CNN(1).to(device)
loss = nn.CrossEntropyLoss()
optimizer = optim.SGD( model.parameters(), lr = learning_rate3,  momentum=0.9 )
EPOCHS = 50
train_loss =  []
train_acc = []
test_acc = []

print(" Batch Size = 64 \n")

for epoch in range(EPOCHS):
    

    running_loss = 0
    correct_predictions = 0
    
    for batch_index, (image_data, classes) in enumerate(train_loader_64):
        
        X = image_data.to(device)
        y = classes.to(device)
        
        #X = X.view(X.shape[0], -1)  ## do this for the FCC part
        
        logits = model.forward(X)
        
        predictions = torch.argmax(logits, dim = 1)
        
        running_loss += loss(logits, y)
        
        #print(classes)
        correct_predictions += torch.sum(predictions == y)
        
        optimizer.zero_grad()
        
    totalLoss = running_loss/(batch_index + 1)
    
    totalLoss.backward()
    
    optimizer.step()
    
    epoch_loss = running_loss.item()/(batch_index + 1)
    epoch_acc = correct_predictions/(60000)
    
    train_loss.append(epoch_loss)
    train_acc.append(epoch_acc)
    test_acc.append(test_accuracy(model, test_loader, 0, True).item())
    
    print("Epoch: {} ........... Training Accuracy: {:.4f}%.....Training Loss: {:.4f}.....Test Accuracy : {:.4f}%".format(epoch + 1, epoch_acc*100, epoch_loss, test_accuracy(model, test_loader, 0 ,True).item()))

visualise(EPOCHS, train_loss, train_acc, test_acc, 64)

TestAcc.append(test_accuracy(model, test_loader, 0, True).item())
TrainAcc.append(test_accuracy(model, train_loader_256, 0, False).item())
print("Batch Size = 64\n")
print(" Testing Accuracy: {:.4f}%   :   Training Accuracy: {:.4f}% ".format(test_accuracy(model, test_loader, 0, True).item(), test_accuracy(model, train_loader_256, 0, False).item()))

batches = [256, 128, 64]

fig = plt.figure(figsize = (16, 5)) 
    #plt.title("Learning Rate = 0.1",  fontsize = 20,fontname="Times New Roman Bold")
    plt.subplot(121)
    plt.plot(batches, TestAcc,'r-',label='Testing') 
    plt.legend()
    plt.title("Testing Accuracy vs Batch Size", fontsize = 20,fontname="Times New Roman Bold")
    plt.xlabel('Batch Size', fontsize = 16)
    plt.ylabel('Accuracy', fontsize = 16)
    
    plt.subplot(122)
    plt.plot(batches,TrainAcc,'g-',label='Training') 
    plt.legend()
    plt.title("Training Accuracy vs Batch Size", fontsize = 20,fontname="Times New Roman Bold")
    plt.xlabel('Batch Size',fontsize = 16)
    plt.ylabel('Acc', fontsize = 16)

##### Question 6a) Conclusion

"""Question 6a) From the Graph Plotted above, it is evident that a lower Batch Size gives us a better Training and Testing Accuracy. Hence a smaller Batch Size say Batch size = 64 is the Optimal One

# **Question 6 B** :Deciding Learning Rate
"""

learning_rate1 = 0.025
learning_rate2 = 0.05
learning_rate3 = 0.1
learning_rate4 = 0.2
learning_rate5 =  0.5

LearningRateOptions = [learning_rate1, learning_rate2, learning_rate3, learning_rate4, learning_rate5]

def Train50Epochs(learning_rate, batch_size, train_loader):
    """
    We take the LearningRate and Batch size hyperparameters in this function and train the Neural Ntework for 50 Epochs
    We return the losses and other Model specifications

    """

    model = CNN(1).to(device)
    loss = nn.CrossEntropyLoss()
    optimizer = optim.SGD( model.parameters(), lr = learning_rate,  momentum=0.9 )
    EPOCHS = 50

    train_loss =  []
    train_acc = []
    test_acc = []

    print(" Batch Size = ", batch_size, "\n")

    for epoch in range(EPOCHS):
        

        running_loss = 0
        correct_predictions = 0
        
        for batch_index, (image_data, classes) in enumerate(train_loader):
            
            X = image_data.to(device)
            y = classes.to(device)
            
            #X = X.view(X.shape[0], -1)  ## do this for the FCC part
            
            logits = model.forward(X)
            
            predictions = torch.argmax(logits, dim = 1)
            
            running_loss += loss(logits, y)
            
            #print(classes)
            correct_predictions += torch.sum(predictions == y)
            
            optimizer.zero_grad()
            
        totalLoss = running_loss/(batch_index + 1)
        
        totalLoss.backward()
        
        optimizer.step()
        
        epoch_loss = running_loss.item()/(batch_index + 1)
        epoch_acc = correct_predictions/(60000)
        
        train_loss.append(epoch_loss)
        train_acc.append(epoch_acc)
        test_acc.append(test_accuracy(model, test_loader, 0, True).item())
        
        print("Epoch: {} ........... Training Accuracy: {:.4f}%.....Training Loss: {:.4f}.....Test Accuracy : {:.4f}%".format(epoch + 1, epoch_acc*100, epoch_loss, test_accuracy(model, test_loader, 0, True).item()))

    return model, train_loss, train_acc, test_acc

## Here er try out the different Learning rates
TestAcc = []
TrainAcc = []

for learning_rate in LearningRateOptions:
     
     print(" Training for Learning Rate = {} \n\n\n".format(learning_rate))
     print('\n')
     model, train_loss, train_acc, test_acc = Train50Epochs(learning_rate, 64, train_loader_64)
     TestAcc.append(test_acc)
     TrainAcc.append(train_acc)

TestAcc = np.array(TestAcc)
TrainAcc = np.array(TrainAcc)
BestTestError = 100 - TestAcc[:, 49]
BestTrainError = 100 -  TrainAcc[:, 49]

LearningRateOptions

### Plotting the test accuracies Vs Epochs for different Learning rates
fig = plt.figure(figsize=[15,5]) 
plt.subplot(121)
plt.title("Acc vs Epoch",  fontsize = 20,fontname="Times New Roman Bold")
plt.plot(range(50),TestAcc[0, :],'r-',label='Batch size=64,lr=.025') 
plt.plot(range(50),TestAcc[1, :],'r-',color='blue',label='Batch size=64,lr=.05') 

plt.legend()
plt.xlabel('Epochs')
plt.ylabel('Test Accuracy')
plt.subplot(122)
plt.title("Acc vs Epoch",  fontsize = 20,fontname="Times New Roman Bold")
plt.plot(range(50),TestAcc[3, :], 'g-',label='Batch size=64,lr=.2') 
plt.plot(range(50),TestAcc[4, :],'g-', color='blue',label='Batch size=64, lr=.5') 
 
plt.legend()
plt.xlabel('Epochs')
plt.ylabel('Test Accuracy')

fig = plt.figure(figsize = (10, 6)) 
#plt.title("Learning Rate = 0.1",  fontsize = 20,fontname="Times New Roman Bold")

plt.plot(LearningRateOptions, BestTestError,'r-',label='Testing') 
plt.legend()
plt.title("Best Testing Error % vs Learning Rate", fontsize = 20,fontname="Times New Roman Bold")
plt.xlabel('Learning Rate', fontsize = 16)
plt.ylabel('Error %', fontsize = 16)



"""Question 6B) Here it is evident that if the learning rate is increased then our Testing Error decreases, hence we need to Train our model with a higher Learning Rate, i.e Learning Rate = 0.1

Conclusion: 6b) Learning Rate = 0.1 gives the best test accuarcy. So I would prefer learning rate = 0.1 for this problem

We also need to note that If the Learning Rate is lower then the convergence is slower, hence we would need to train it for more number of Epochs for lwer learning Rate. For 50 Epochs, learning rate 0.5 is the most desirable
"""



"""# Question 6C: Stochastic Gradient Descent with **Restarts**"""

### The Algorithm that we use is We initialise the Learning Rate at 0.5, which gave the best Results as per 6 B)
## We train the algorithm for say 100 Epochs and after 50 for evry 10 Epochs we reduce the Learning Rate by 0.2 till 70 epochs
### Then from 70 Epochs to 100 Epochs we divide the learning Rate by 2 for every 10 epochs
## So roughly Learning rate algorithm is

Epoch no.              Learning Rate
0 - 50                 0.5
50 - 60                0.3    # -0.2
60 - 70                0.1
70 - 80                0.05   # / 2
80 - 90                0.025
90 - 100               0.0125

### This is the Training Cell,
## We have encoded the Learning Rate Restart in the function

model = CNN(1).to(device)
loss = nn.CrossEntropyLoss()

EPOCHS = 100

train_loss =  []
train_acc = []
test_acc = []

intitial_learning_rate = 0.5 ##

optimizer = optim.SGD( model.parameters(), lr = 0.5,  momentum=0.9 )
lr = intitial_learning_rate
for epoch in range(EPOCHS):
        
        if(epoch >= 50 and epoch < 70):         ## First LR restart ## Linear decrease
            lr = intitial_learning_rate - 0.02*(epoch - 50)
            optimizer = optim.SGD( model.parameters(), lr = intitial_learning_rate - 0.02*(epoch - 50),  momentum=0.9 )
        
        if(epoch >= 70 and (epoch %10) == 0):  ## More LR restart, as we go closer to 100 Eochs we make it exponential decrease instead of linear
           lr = 0.1/(2**((epoch - 60)/10))
           optimizer = optim.SGD( model.parameters(), lr = lr,  momentum=0.9 )



        running_loss = 0
        correct_predictions = 0
        
        for batch_index, (image_data, classes) in enumerate(train_loader_64):
            
            X = image_data.to(device)
            y = classes.to(device)
            
            #X = X.view(X.shape[0], -1)  ## do this for the FCC part
            
            logits = model.forward(X)
            
            predictions = torch.argmax(logits, dim = 1)
            
            running_loss += loss(logits, y)
            
            #print(classes)
            correct_predictions += torch.sum(predictions == y)
            
            optimizer.zero_grad()
            
        totalLoss = running_loss/(batch_index + 1)
        
        totalLoss.backward()
        
        optimizer.step()
        
        epoch_loss = running_loss.item()/(batch_index + 1)
        epoch_acc = correct_predictions/(60000)
        
        train_loss.append(epoch_loss)
        train_acc.append(epoch_acc)
        test_acc.append(test_accuracy(model, test_loader, 0, True).item())
        
        print("lr: {}  Epoch: {} ........... Training Accuracy: {:.4f}%.....Training Loss: {:.4f}.....Test Accuracy : {:.4f}%".format(lr, epoch + 1, epoch_acc*100, epoch_loss, test_accuracy(model, test_loader, 0, True).item()))

test_acc = np.array(train_acc)

lr = []          ## We keep LR constant, then decrease linearly, then exponentially ## One expt, this gave best results
for i in range(50):
  lr.append(0.5)
for i in range(50, 70):
  lr.append(0.5 - 0.02*(i - 50) )

for i in range(70, 100):
  lr.append(0.1/(2**((i - 60)/10)))

"""The following Cell shows How I varied the Learning Rate with Epochs"""

plt.figure(figsize = (8, 5))
plt.plot(range(100), lr)
plt.title(" Variation of Learning Rate with Epochs")
plt.xlabel(" Epochs ")
plt.ylabel("Learning Rate")

visualise(EPOCHS, train_loss, train_acc, test_acc, 64)



"""Question 6c) As we can see that Loss Function Reaches a high value and more or less remains the same afterwards

This is done because as we move the parameters closer to the Optimal value, we need to slow down the update otherwise we may OVERSHOOT past the optimal value. Hence we gradually decrease learning rate and allow or Algorithm to take smaller Gradient steps as we go closer to the Optimal Loss function

It is conclusive that if we Gradually decrease learning rate, our model converges to a better optimal value of Cost and gives a better Test Accuracy. In a nutshell we take baby steps as we go closer to our Optimal value and the size of Baby steps decreases exponentially as we go closer.

A higher learning rate may cause us to Overshoot from the Minima and go past the Minimum value, this will prevent our Gradient descent from converging. Hence we need to have a smaller learning rate and decreasing the learning rate stepwise as we go closer to minima ensures a better convergence
"""

